{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdf61c1",
   "metadata": {},
   "source": [
    "### Time Series Forecasting Methods\n",
    "\n",
    "**Autoregression (AR)**\n",
    "\n",
    "**Moving Average (MA)**\n",
    "\n",
    "**Autoregressive Moving Average (ARMA)**\n",
    "\n",
    "**Autoregressive Integrated Moving Average (ARIMA)**\n",
    "\n",
    "**Seasonal Autoregressive Integrated Moving-Average (SARIMA)**\n",
    "\n",
    "**Seasonal Autoregressive Integrated Moving-Average with Exogenous Regressors (SARIMAX)**\n",
    "\n",
    "**Vector Autoregression (VAR)**\n",
    "\n",
    "**Vector Autoregression Moving-Average (VARMA)**\n",
    "\n",
    "**Vector Autoregression Moving-Average with Exogenous Regressors (VARMAX)**\n",
    "\n",
    "**Simple Exponential Smoothing (SES)**\n",
    "\n",
    "**Holt Winterâ€™s Exponential Smoothing (HWES)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8880092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa9391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101.00328501]\n"
     ]
    }
   ],
   "source": [
    "# AR \n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1, 100)]\n",
    "# fit model\n",
    "model = AutoReg(data, lags=1)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb452c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75.75773531]\n"
     ]
    }
   ],
   "source": [
    "#MR\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1, 100)]\n",
    "# fit model\n",
    "model = ARIMA(data, order=(0, 0, 1))\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b20fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54670544]\n"
     ]
    }
   ],
   "source": [
    "#ARMA \n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = [random() for x in range(1, 100)]\n",
    "# fit model\n",
    "model = ARIMA(data, order=(2, 0, 1))\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829f1d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.00586428]\n"
     ]
    }
   ],
   "source": [
    "# ARIMA \n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1, 100)]\n",
    "# fit model\n",
    "model = ARIMA(data, order=(1, 1, 1))\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data), typ='levels')\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1037ace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.00139492]\n"
     ]
    }
   ],
   "source": [
    "#SARIMA \n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1, 100)]\n",
    "# fit model\n",
    "model = SARIMAX(data, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
    "model_fit = model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7fac8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.9838175]\n"
     ]
    }
   ],
   "source": [
    "# SARIMAX \n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data1 = [x + random() for x in range(1, 100)]\n",
    "data2 = [x + random() for x in range(101, 200)]\n",
    "# fit model\n",
    "model = SARIMAX(data1, exog=data2, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
    "model_fit = model.fit(disp=False)\n",
    "# make prediction\n",
    "exog2 = [200 + random()]\n",
    "yhat = model_fit.predict(len(data1), len(data1), exog=[exog2])\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b672c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51192488 1.19238635]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# VARMA example\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from random import random\n",
    "# contrived dataset with dependency\n",
    "data = list()\n",
    "for i in range(100):\n",
    "    v1 = random()\n",
    "    v2 = v1 + random()\n",
    "    row = [v1, v2]\n",
    "    data.append(row)\n",
    "# fit model\n",
    "model = VARMAX(data, order=(1, 1))\n",
    "model_fit = model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = model_fit.forecast()\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38db309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.63560898]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SES example\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1, 100)]\n",
    "# fit model\n",
    "model = SimpleExpSmoothing(data)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc6602b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.04482762]\n"
     ]
    }
   ],
   "source": [
    "# HWES example\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1, 100)]\n",
    "# fit model\n",
    "model = ExponentialSmoothing(data)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66642e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
